---
title: "Chapter 01 of DSUR"
author: "Peter Baumgartner"
date: "`r Sys.Date()`"
output:
  html_notebook:
    fig_caption: yes
    number_sections: yes
    pandoc_args: --number-offset=0,0
    toc: yes
    toc_depth: 4
  word_document:
    toc: yes
    toc_depth: '4'
  pdf_document:
    pandoc_args: --number-offset=0,0
    toc: yes
    toc_depth: '4'
    latex_engine: xelatex
  github_document:
    toc: yes
    toc_depth: 4
  html_document:
    fig_caption: yes
    keep_md: yes
    number_sections: yes
    pandoc_args: --number-offset=0,0
    toc: yes
    toc_depth: 4
---
```{r label = "global-options", echo=FALSE, highlight=TRUE}
knitr::opts_chunk$set(
        message = F,
        error = F,
        warning = F,
        comment = NA,
        highlight = T,
        prompt = T
        )

### install and load some important packages
### https://github.com/tidyverse/tidyverse
if (!require("tidyverse"))
        {install.packages("tidyverse", repos = 'http://cran.wu.ac.at/')
        library(tidyverse)}

### above command installed and loaded the core tidyverse packages:
# ggplot2: data visualisation
# tibble:  a modern take on data frames
# tidyr:   data tidying
# readr:   data import (csv, tsv, fwf)
# purrr:   functional R programming
# dplyr:   data (frame) manipulation
# stringr: string manipulation
# forcats: working with categorial varialbes


### My personal reminder for other important packages:
### Working with times:
# hms, for times.
# lubridate, for date/times.

### Importing other types of data:
# feather, for sharing with Python and other languages.
# haven, for SPSS, SAS and Stata files.
# httr, for web apis.
# jsonlite for JSON.
# readxl, for .xls and .xlsx files.
# rvest, for web scraping.
# xml2, for XML.

### Modelling
# modelr, for modelling within a pipeline
# broom, for turning models into tidy data
```

# Basics: Measures of central tendency

## How to get a small data set into R?

Number of friends of 11 Facebook user: 
108, 103, 252, 121, 93, 57, 40, 53, 22, 116, 98.

### Assign values to a vector

```{r assign-values-to-vector}
# number of facebook friends = nff
nff <- c(108, 103, 252, 121, 93, 57, 40, 53, 22, 116, 98)
nff <- sort(nff)
nff
```

### Read data values from keyboard

After running the following code you have to set your curso into the console and provide the data. There are 2 possibilities:
* Enter the data manually and separate each entry with ENTER
* Copy a string of data (e.g. from a PDF table), where each data is spearated by a blank

In both cases: Terminate the input with an extra ENTER

```{r read-data-from-keyboard, eval=FALSE}
nff_scan <- as.vector(scan(file = ""))
nff <- sort(nff_scan)
nff_scan
```

## Mode

There is no mode-function in the base R module. See https://bit.ly/R-mode.
But there are many possibilites to programm this function.

Before I will demonstrate this, I need to add another number into the data set in order to get the frequencey of one number higher than the others.

```{r add-number-to-vector}
nff_mode <- c(nff, 53)
```

Variante 1: Simple but goot!

```{r compute-mode}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
Mode(nff_mode)
```

Version 2: with NA

```{r compute-mode-with-na}
Mode <- function(x, na.rm = FALSE) {
    if (na.rm) {
        x = x[!is.na(x)]
    }
    ux <- unique(x)
    ux[which.max(tabulate(match(x, ux)))]
}
Mode(nff_mode)
```

```{r compute-mode-with-modeest-pkg}
library(modeest)
mlv(nff_mode, method = "mfv")
```

## The Median

### Just the function

```{r compute-median}
median(nff)
```

### Without outlier

```{r compute-median-2}
median(nff[1:10])

```

## The mean

### Just the function
```{r compute-mean}
mean(nff)
```

### Without outlier

```{r compute-mean-2}
mean(nff[1:10])
```

### With NA Value not removed

```{r compute-mean-3}
mean(nff[c(1:10, NA)])
```

### With NA Value removed
```{r compute-mean-4}
mean(nff[c(1:10, NA)], na.rm = TRUE)
```

### With outlier but trimmed

```{r compute-mean-5}
mean(nff, trim = 0.1)
mean(nff[2:10])
```

## The range

### Just the function

```{r compute-range}
x <- range(nff)
xr <- x[2] - x[1]
cat("Range:", x[2], "-", x[1], "=", xr)
```

### Without outlier


```{r compute-range-2}
x <- range(nff[1:10])
xr <- x[2] - x[1]
cat("Range:", x[2], "-", x[1], "=", xr)
```

## Upper and Lower Quartile

```{r compute-upper-and-lower-quartile}
quantile(nff, type = 1)
```


## The Interquartile Range

### Just the function

```{r compute-IQR}
IQR(nff)
```

### Computed with type = 1

This measure has 9 different calculation methods (quantile algorithms) which really matter because of their big differences. Standard is type = 7 (results in 57), whereas type = 1 results in 63.

```{r compute-IQR-2}
IQR(nff, type = 1)
```

## Self-Test p.25

```{r self-test-p25}
treadmill <- c(18,16,18,24,23,22,22,23,26,29,32,34,34,36,36,43,42,49,46,46,57)
Mode <- function(x, na.rm = FALSE) {
    if (na.rm) {
        x = x[!is.na(x)]
    }
    ux <- unique(x)
    tab <- tabulate(match(x, ux)); 
    ux[tab == max(tab)]
    
}
Mode(treadmill)
median(treadmill)
mean(treadmill)
quantile(treadmill, type = 6)
range(treadmill)
IQR(treadmill, type = 6)

```

## Self-Test p.27

What's the probability that someone wo threw themselves of Beachy Head was 30 years or older?

* First we convert 30 into a z-score. Suppose the mean of the suicide scores was 36, and the standard deviation 13; then 30 will bekomme (30-36)/13 = `r n <- (30-36)/13; n`.
* We then look up this value in the column labelled "Bigger Portion" (i.e., the area above the value `r n`).
* I get the value of 32.28%, or put another way, there is a chance of 32.28% that a suicide victim was aged 30 or less. We can also say that there is a 67.72% chance that a suicide victim wa older than 30.
